# Java并发编程

## synchronized

### 底层原理

是和jvm指令和monitor有关系

你如果用到了synchronized关键字，在底层编译后的jvm指令中，会有**monitorenter和monitorexit**两个指令

monitor里面有一个计数器，从0开始的。如果一个线程要获取monitor的锁，就看看他的计数器是不是0，如果是0的话，那么说明没人获取锁，他就可以获取锁了，然后对计数器加1

### 加锁

一个线程第一次synchronized那里，获取到了myObject对象的monitor的锁，计数器加1，然后第二次synchronized那里，会再次获取myObject对象的monitor的锁，这个就是重入加锁了，然后计数器会再次加1，变成2

其他的线程在第一次synchronized那里，会发现说myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入block阻塞状态，什么都干不了，就是等着获取锁

接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit的指令，在底层。此时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后，计数器是0

然后后面block住阻塞的线程，会再次尝试获取锁，但是只有一个线程可以获取到锁

在对象内的方法上加入synchronized修饰符，在方法调用时，会对对象进行加锁，也就是只有一个线程能获取到锁。

在多线程的情况下，就会串行化，会降低代码的执行效率

## CAS（compare and set）

**取值、询问、修改** 

线程操作对象时，先获取到对象的值，然后进行值更改，然后进行设置，在设置时对对象的值和获取的值进行对比，如果一样，证明这期间是没有线程对数据进行更改，则新值设置成功，但是如果值发生了变化，则设置失败，再次进行取值和设置值。

**原子性是在硬件级别保证的**

## ConcurrentHashMap

在多线程中，如果多个线程需要对map进行操作，那么就会出现原子性问题，此时使用synchronized进行加锁，如果对同一位置的put进行加锁，是没有问题的，但是对不同位置的数据进行变更时，加锁则没有必要，java的多线程包则推出了ConcurrentHashMap，它默认实现了线程安全性

### 线程安全的底层原理

+ JDK 1.7之前是多个数组进行分段加锁，每个数组一个锁

+ JDK 1.8后进行锁粒度的优化。一个数组每个元素进行put时加不同的锁，如果两个线程在同一个位置进行put时，采取CAS策略，保证只有一个线程能执行操作

## AQS

**抽象队列式同步器**

### 原理

多线程访问的时候，多个线程基于CAS同时尝试在AQS中进行加锁，这时候会有一个线程加锁成功，其余的加锁失败，加锁成功的线程更新到AQS中，加锁失败的进入AQS的等待队列中，加锁成功的线程在完成后释放锁，这个时候会唤醒等待队列队头的线程，基于CAS进行加锁，这个时候加锁成功继续运行逻辑

这是一个非公平锁，也就是如果在唤醒线程时有一个新的线程进来，则新的线程有可能抢夺到锁，则唤醒的线程需要重新进入队列里进行排队

如果需要做公平锁，则需要在构造函数上传入一个true

```java
ReentrantLock lock = new ReentrantLock(true);
```

此时进来的线程需要先判断等待队列里是否有线程，如果有则进入等待线程，没有则进行锁的占用

## 线程池

系统是不允许无限制的创建线程的，会构建一个线程池，有一定量的线程，让他们执行各种任务，任务执行完成后不销毁自己，等待下一次调用

### 底层工作原理

```java
ExecutorService threadPool = Executors.newFixedThreadPool(3) -› 3: corePoolSize
 
threadPool.submit(new Callable() {
       public void run() {}
});
```

提交任务，先查看线程池的线程数量是否小于corePoolSize，如果小于则创建线程来执行任务，执行完以后线程不会消亡，该线程尝试从一个无界的LinkedBlockingQueue获取新的任务，如果没获取到，则线程阻塞

不断的提交任务，不断的创建线程，直到线程数量达到corePoolSize，这时候则不再新建线程，任务进入到无界的LinkedBlockingQueue，阻塞的空闲线程会直接获取到任务进行处理

### 核心配置参数

+ corePoolSize：核心线程数量
+ maximumPoolSize：最大线程数量
+ keepAliveTime：额外线程无任务最多存活时间
+ new ArrayBlockingQueue‹Runnable›(200)：任务队列

核心线程满了以后，任务会进入任务队列，当队列塞满了就会创建额外的线程去消费任务，数量限制为最大线程数量。如果还是处理不过来，则进行拒绝策略进行拒绝。在任务处理完以后，额外线程阻塞，在keepAliveTime后未接到任务，则线程死亡

### 无界队列的问题（线程池中）

在远程服务异常的情况下，使用无界阻塞队列，会导致队列变得很大，导致内存飙升，还有可能会导致OOM内存溢出

### 拒绝策略（建议）

在有界队列塞满了以后，而且线程池也满了，导致后续任务不能进入队列了，可以考虑自定义一个拒绝策略，建议可以把这个任务信息持久化写入磁盘里去，后台专门启动一个线程，后续等待你的线程池的工作负载降低了，他可以慢慢的从磁盘里读取之前持久化的任务，重新提交到线程池里去执行

如果大量创建线程会导致大量占用内存资源，甚至导致系统崩溃，即便没崩溃也会导致cpu负载过高

### 任务丢失情况

机器在宕机的情况，可能会导致线程池里面队列里的任务丢失

**处理方案：**

真实案例：群发消息时避免系统宕机时发送情况，记录每次入队列的数据数量，每次拉取数据时去更新该表的数据情况，这样，即便是系统宕机时也能确定到数据的执行大概位置，每次执行成功时更新每一条数据的状况（线程不多的情况下），这样能精准定位到每一条数据的执行情况

在系统重启时，后台线程进行数据库扫描任务然后再执行（或者提供接口）

## Java的内存模型

### 基础原理

对象实例化后都会在堆内存中

主内存：java中在运行过程中所有的数据都会放在主内存中

工作内存：CPU级别缓存，在每个线程创建的时候就会产生一个工作内存

线程在操作时，会先将数据从主内存中读取（read）并加载（load）到工作内存，在工作内存中对数据进行操作（use），线程计算后将数据重新设置到工作内存（assign），然后将操作完的数据尝试往主内存写（store），最后会将数据写到主内存中（write）。

**在多线程并发的情况下，会造成工作内存读取到同一个主线程的数据，在处理后造成数据的问题**

### 原子性

- 有原子性：多线程情况下，要求一个数据**只能被一个线程操作**，在完成后其他线程才能对数据进行操作
- 没有原子性：多线程可以同时对一个数据进行操作

### 可见性

- 没有可见性：在多线程的情况下，有一个线程更新了数据，但是别的线程并**不能第一时间获取到数据变化**
- 有可见性：在多线程的情况下，有线程更新了数据，要求其他线程**强制重新获取到数据**

### 有序性

在代码进行编译时，为了效率或者其他原因会进行**指令重排**，导致在有逻辑顺序的线程执行时，会先执行一些后面的指令操作，导致逻辑混乱引起的代码异常

- 具备有序性：不会发生指令重排
- 不具备有序性：会发生指令重排

## volatile

volatile关键字**主要是用来解决可见性和有序性的**，在有些罕见的情况下，可以**有限的保证原子性**，主要不是用来保证原子性的

### 可见性基础原理

在对属性使用volatile修饰后，如果有线程对数据进行了操作，在回写主内存后，会对**其他线程使用的这个字段进行失效**，会促使其他线程重新从主内存中加载数据到工作内存中

### happens-before原则

1. **程序次序原则**：一个线程内，按照代码的顺序进行执行
2. **锁定规则**：一个解锁操作一定在后一个加锁前执行
3. **volatile变量规则**：一个变量的写操作一定发生在读操作之前
4. **传递规则**：A操作先于B操作，B操作先于C操作，可以得出A操作先发生于C操作
5. **线程启动规则**：线程的start操作比线程内的任何操作都先执行
6. **线程中断规则**：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
7. **线程终结规则**：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
8. **对象终结规则**：一个对象的初始化完成先行发生于他的finalize()方法的开始
   规则制定了在一些特殊情况下，不允许编译器、指令器对你写的代码进行指令重排，必须保证你的代码的有序性

### 时序性基础原理

volatile会让变量必须进行先写再读，这样可以有效的避免了程序会进行指令重排，会按照写的代码顺序来执行

### 内存屏障

1. 内存屏障避免指令重排（有序性）
2. 执行写操作的时候，jvm会发送lock前缀指令，CPU在计算完成以后会强制将值写回主内存，EMSI缓存一致性协议会让各个CPU对总线进行嗅探，判断本地缓存是否被人修改，如果修改了，就会将本地缓存数据过期做重新加载（可见性）