# 高并发

限流、熔断、降级

## 分库分表

### 中间件

1. cobar

   阿里b2b团队开发，属于代理层解决方案。使用量不大，不支持读写分离、存储过程、跨库join和分页操作

2. TDDL

   淘宝团队开发，属于客户端方案。不支持jion、多表查询。支持读写分离，还需要依赖淘宝的diamond配置管理系统。使用量不大

3. atlasa

   360开源，代理层次解决方案。社区活跃度不高。使用量不大

4. sharding-jdbc

   当当开源，属于客户端方案。sql语法支持的较多，没有太多限制，2.0版本后支持分库分表、读写分离、分布式id生成，柔性事务（最大努力送达型事务，TCC），社区活跃，使用量较大

5. mycat

   基于cobar改造的，属于代理层解决方案，支持功能完善。目前非常火而且很流行的中间件，社区活跃。用户量多

### 水平拆分和垂直拆分

1. 水平拆分

   水平拆分将一个表的数据弄到多个库里面去，表结构完全一样，每个库表里放的数据不一样，所有库表里的数据加起来才是整体的数据。意义在于将数据均匀放在更多的库里，使用多个库抗更高的高并发，扩容更加方便

2. 垂直拆分

   把一个有很多字段的表拆分到多个表或者库里，将访问频率或者大字段进行单表存储。因为数据库是有缓存的。访问频率高的少字段可以存储的更多

### 分库分表迁移方案

sharding-jdbc和mycat官网有示例

+ 长时间分库分表

  停机进行分库分表，通过后台编写的临时程序通过中间件进行数据分散，分库分表完成后进行服务重启

+ 不停机双写方案

  对进来的数据，即写原来的库，也写数据库中间件（双写），后台进行一个数据迁移的临时工具，将老库的数据不断进行读取并通过中间件进行数据分发。在临时迁移数据中对数据进行查询，如果没有，则直接进行迁移，如果有，则对时间戳进行比较，如果数据新，则进行数据覆盖。数据每完成一轮，要对数据的一致性进行校验，对不同的数据进行再次同步。当双方数据一致时，则数据迁移完成，在后续更新中更新代码，将单库单表的数据进行删除。

### 分库分表的扩容方案

+ 停机扩容

  停机通过数据工具进行数据导出和分发

+ 优化方案

  设计的时候进行多库设计，迁移时对库进行迁移

## 全局id

1. 设计生出主键的库，全局仅一个，然后来生出id后进行到各个库里面去进行id设置（简单，但是有瓶颈）

2. uuid

   在本地生成UUID，将 - 替换掉生成的id，但是缺点过长

3. 获取系统当前时间

   高并发情况下会有重复的情况

   可以通过别的字段值来进行拼接（设备对接数据唯一标识方案）

4.雪花id（snowflake）

+ 64位long型的id，转换为2进制
+ 最多支持32个机房，每个机房最多支持32台机器
+ 每秒可以生产4096000个id

## mysql读写分离

1. 原理

   基于主从架构，主库有一个后台的IO线程，有一个binlog日志，从库也有一个IO线程，从库基于IO连接会从主库去请求binlog日志，从库会将数据写到relay日志，从库的sql线程会不断的从relay日志中不断的读取sql执行，串行化的。但是也就有数据延迟的问题

2. 延迟

   少量数据时，不存在延迟问题。主库的写并发达到1000左右，会有几毫秒的延迟。写并发达到2000，从库会有几十毫秒的样子

3. 数据丢失

   主库写入数据时，在还没同步时就宕机了，此时从库切换为主库就会导致数据丢失。

   + mysql提供了半同步复制，即至少同步一台从库才认为写成功。
   + 并行复制，开多个sql线程，每个线程从relay日志里读一个库的日志进行同放

4. 解决延迟问题

   + 对于数据时效性不高的，可以直接使用主从架构
   + 对于读取数据要求很及时的，可以采取强行读主库保证数据的一致性
   + 分库，将一个主库拆分为多个主库，则写并发降低，则主从延迟可以忽略
   + 打开mysql的并行复制
   + 代码层面进行控制（第二条）

## hystrix

1. 资源隔离

   让系统中某一块东西，在故障的情况下只能使用那么多资源，不会耗尽所有的资源，比如线程

2. 限流

   高并发流量进入，拒绝超额的流量

3. 熔断

   系统后端依赖出现问题，比如mysql，每次请求都报错，则熔断，后续请求不接收，拒绝访问，一定时间后尝试依赖是否恢复

4. 降级

   mysql挂了，系统发现了，自动降级，从内存里存的少量数据中提取一些数据出来

5. 运维监控

   监控+报警+优化，各种异常情况，有异常就报警，优化一些系统的配置和参数