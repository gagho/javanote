# 面试点一：消息队列（MQ）

## MQ的三大作用

+ 解耦

  避免每个系统在调用的别的系统时都需要进行强耦合的开发工作

+ 削峰

  避免系统在同一时间接收到过量请求导致系统崩溃

+ 异步

  避免在进行主流程不相关的工作时间堆积在主流程的时间上

## MQ的缺陷

+ 系统可用性降低

  在MQ故障时，系统不能发送消息到MQ，则消费者不能进行消费，即为系统崩溃

+ 系统复杂性提高

  系统考虑的问题多，进而导致复杂性提高（消息丢失，重复消费，消息堆积）

+ 一致性的问题

  多系统情况下，需要一致完成才算完成的情况下，有系统执行失败，则会导致系统数据异常

## 常见MQ的优缺点

### ActiveMQ

+ 单机吞吐量：W级
+ topic数量对吞吐量的影响：无
+ 时效性：ms级
+ 可用性：高，基于主从架构
+ 消息可靠性：有较低概率丢失数据
+ 核心特点：MQ领域的功能及其完善
+ 优势：非常成熟，业内大量使用
+ 劣势：偶尔有消息丢失，开源社区维护的较少，主要用于解耦和异步，较少在大规模吞吐上使用

### RabbitMQ

+ 单机吞吐量：W级
+ topic数量对吞吐量的影响：无
+ 时效性：微秒级
+ 可用性：高，基于主从架构
+ 消息可靠性：一般来说不丢
+ 核心特点：并发能力很强，延时很低
+ 优势：性能好，开源提供的界面好，易于使用，社区活跃
+ 劣势：吞吐量低，动态扩展很麻烦，很难读源码，很难定制和掌握，基本只能依赖于开源社区

### RocketMQ

+ 单机吞吐量：10W级
+ topic数量对吞吐量的影响：达到几百、几千个级别，吞吐量有小幅度的下降
+ 时效性：ms级
+ 可用性：非常高，分布式架构
+ 消息可靠性：参数优化的情况下可以做到0丢失率
+ 核心特点：MQ领域的功能较为完善，分布式，扩展性好
+ 优势：简单易用，阿里大规模使用，吞吐量大，性能好，分布式扩展方便，社区维护好，支持复杂MQ场景，java源码，可以定制MQ
+ 劣势：社区活跃度相对一般，文档相对较少，阿里系抛弃的话可能会无人维护，技术好的公司还是可以使用的

### Kafka

+ 单机吞吐量：10W级
+ topic数量对吞吐量的影响：在几十到几百时，吞吐量有较大的下降
+ 时效性：ms级以内
+ 可用性：非常高，一个数据有多个副本，少数设备宕机不会导致数据丢失
+ 消息可靠性：参数优化的情况下可以做到0丢失率
+ 核心特点：功能简单，主要支持简单MQ功能，大数据实时计算和日志采集上被大量使用
+ 优势：超高的吞吐量，任意扩展，适合大数据领域
+ 劣势：功能少

### 总结

早期使用ActiveMQ较多，但是由于吞吐量及功能限制，后面开始使用RabbitMQ是RabbitMQ的语言特性阻止了大量的java工程师的研究，几乎处于不可控状态，但是有稳定的支持，且社区活跃度也高

现在也有大量公司使用RocketMQ，但是因为是阿里研发，有可能会出现后期无人维护的情况，在公司技术层面比较高的情况下建议

所以中小型公司建议用RabbitMQ，大型工时使用RocketMQ做为基础架构很不错

Kafka较适合大数据的实时计算和日志采集等场景，用Kafka是业内标准，社区活跃度高

## 如何保证MQ的高可用性

### RabbitMQ

RabbitMq有三种模式：单机模式、普通集群、镜像集群

1. 普通集群

   在多台设备上启动多个MQ实例，创建的queue只会放到一个实例上，每个实例都会同步queue。消费的时候会从queue所在的实例上拉取数据。没做分布式就是一个普通集群，拉取数据时只能随机连接实例拉取数据或者固定连接实例拉取数据，前者会导致数据拉取的开销，后者导致单实例性能的瓶颈

2. 镜像集群

   和普通集群不一样，创建的queue，元数据和数据都存在每个实例上，写消息时会同步到每个实例上。消费的时候可以从任何节点消费数据。任何一个节点宕机了，其它节点上都有queue的完整数据。

   在管理后台增加镜像集群策略，指定要求数据同步到所有节点，可以要求同步到指定数量节点，创建queue时应用这个策略即可开启

### kafka

broker进程：就是kafka在每台机器上启动的自己的一个进程

1. 架构认识：多个broker组成，每个broker是一个节点，每创建一个topic，topic划分为多个partition，每个partition在不同的broker上，每个partition放一部分数据
2. kafka 0.8之前没有HA机制，也就是如果有设备宕机，会导致数据丢失
3. 多台机器做集群时，每个partition会生成多个副本，但是只有一个partition为leader，其余为follower，当有设备宕机时，则会重新选出leader，读写数据都在leader上

## 如何保证消息消费时的幂等性

重复消费数据不是由MQ来保证的，而是我们开发人员来保证的

### 为什么会出现幂等性问题

以kafka为例：

kafka实际上有个offset的概念，即消息写入时都会有一个offset，代表消息的序号，消费者消费数据后，每隔一段时间，会把自己消费过的offset提交，MQ收到后标识消息已被消费

但是系统宕机在未来得及提交的offset时，重启会导致少数消息再消费一次

### 如何保证幂等性

结合业务思考提供的方案：

1. 数据库写库，根据唯一数据进行查询，无则插入，有则更新
2. 写入redis，可以不用管，redis的set操作天然幂等
3. 生产者生产数据时生成一个全局唯一ID，ID可以存在redis中，消费时去查询一遍，如果是消费过的就不处理
4. 数据库创建唯一索引

总结：幂等性最终是要消费者来保证，结合业务场景进行处理，消费时有记录，并且在消费时做判断

## 如何保证消息不丢失

### 为什么会产生消息丢失

以RabbitMQ为例：

1. 生产者弄丢数据

   网络问题导致在上传MQ时丢失，或者数据上传到MQ，但是MQ内部出错导致数据未保存

2. MQ问题

   MQ接到数据，但消费者还未开始消费，MQ宕机导致数据丢失

3. 消费者问题

   消费者接受到数据，但是在消费过程中宕机导致数据异常，但是MQ认为消费成功

以kafka为例：

+ 唯一一个导致消费者弄丢数据的情况，就是消费者消费到这个消息，消费者自动提交了offset，此时消费者还没消费到数据，就宕机了
+ 数据到leader上，但还未同步到follower上时，leader异常则会导致数据丢失，重新选取的leader上没有最新的数据

### 如何避免消息丢失

1. 生产者丢失数据（网络问题除外）

   + 在代码中进行处理，如果抛出异常，则进行事务回滚（会有阻塞的问题）

   + 设置channel为confirm模式，RabbitMQ会回调接口通知生产者消息是否接收到。生产者进行相应的处理。

2. MQ问题

   + 将queue设置为持久化
   + 将消息设置为持久化
   + 也可以和生产这confirm进行结合，在持久化后再通知生产者

3. 消费者问题

   + 一般问题是打开了自动应答的功能，即在接收到数据时自动告诉MQ消费完成
   + 关闭自动应答（autoAck），在数据处理完以后再进行应答

kafka：

1. 消费者关闭自动提交offset，改成手动提交

2. 设置参数

   + topic 的replication.factor参数：这个值大于1，也就是partition的副本至少有两个
   + 设置min.insync.replicas参数：这个值必须大于1，要求leader至少感知到有一个follower存活
   + 在生产者端设置acks=all，要求每条数据写入所有的replica之后才认为是成功的
   + 在生产端设置restries=MAX，要求写入失败就无限重试

   这样就保证了在切换leader时数据不会丢失，且写数据一定成功

## 如何保证数据顺序一致性

### 顺序错乱的情况

1. rabbitMQ：一个queue，多个consumer
2. kafka：一个topic，一个partition，一个consumer，consumer内部多线程

### 如何保证顺序

1. 创建多个queue，每个消费者消费指定的queue，保证数据按顺序发送到同一个queue里
2. 写入partition中的数据一定是有顺序的，生产者指定一个唯一的key，则这个key的数据一定会写到一个partition中，而且是一定有顺序的，且一个partition一定对应了一个消费者
3. 消费者在多线程时，使用内存队列，将数据对于同一个key的分发到同一个内存队列，每个线程取固定队列中的数据进行处理

## 消息堆积（消息延时及过期失效）

1. 一般是消费者故障导致消息未能及时消费
   1. 快速修复消费者的问题
   2. 临时建立topic，queue数量为当前queue的10倍到20倍
   3. 写一个临时分发数据的程序，从当前的queue里去快速轮询数据存入到临时的queue中
   4. 增设当前10倍到20倍的设备数量部署消费者，进行大量的数据消费
   5. 数据消费完成后，恢复到原有架构

2. 如果是设置了过期时间

   rabbitMQ是可以设置过期消费时间，如果超过时间还没消费，则会被rabbitMQ清理掉。即为数据大量丢失。解决方法只能是在用户使用低峰期重新查询出那批数据，重新灌入MQ中，把白天的数据补回来

3. 消息积压导致MQ快满了

   在第一个方案太慢的情况下，只能进行临时程序对数据进行丢弃，然后再在用户低峰期进行数据补录

## 如何设计MQ(考虑角度)

1. 支持扩容

   参考kafka，分布式

2. 落地磁盘

   顺序写

3. 系统宕机

   做多个副本，进行主从

4. 数据0丢失

   mq的内部机制

总结：

​	将前面的各个特性进行总结考虑